%YAML:1.0

num_threads: 0  # 0  Use the max number of threads of your device.
                #    For some devices, like HUAWEI Atlas200, the auto detected max number of threads might not equivalent to the usable numble of threads. (Some cores(threads) might be reserved for other usage(NPU) by system.)
                # x  It is proper that 1 < x < MAX_THREAD.
                # For now, this parameter is relevant to grid-detector to run in parallel. 

#common parameters
imu: 1
static_init: 1
imu_topic: "/camera/imu"
image_topic: "/camera/color/image_raw"
depth_topic: "/camera/aligned_depth_to_color/image_raw"
output_path: "/home/jiangcx/Documents/ros_ws_rgbd/output/"

#RGBD camera Ideal Range
depth_min_dist: 0.3
depth_max_dist: 6
fix_depth: 1    # 1: feature in ideal range will be set as constant 

frontend_freq: 20 # It should be raised in VO mode(without IMU).
num_grid_rows: 5
num_grid_cols: 6

#camera calibration
model_type: PINHOLE
camera_name: camera
image_width: 640
image_height: 480

distortion_parameters:
   k1: 1.3207978028810621e-01
   k2: -2.5594366837264354e-01
   p1: 8.5582188860743838e-04
   p2: 3.6206216543766428e-03
projection_parameters:
   fx: 601.347290039062
   fy: 601.343017578125
   cx: 329.519226074219
   cy: 238.586654663086

# Extrinsic parameter between IMU and Camera.
estimate_extrinsic: 1   # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.
                        # 1  Have an initial guess about extrinsic parameters. We will optimize around your initial guess.
                        # 2  Don't know anything about extrinsic parameters. You don't need to give R,T. We will try to calibrate it. Do some rotation movement at beginning.
#If you choose 0 or 1, you should write down the following matrix.
#Rotation from camera frame to imu frame, imu^R_cam
extrinsicRotation: # opencv-matrix
   rows: 3
   cols: 3
   dt: d
   data: [ 0.999928,         0.0117514,        0.00233911 , 
          -0.0116881,        0.999608,        -0.0254522 , 
          -0.0026373,        0.0254231,        0.999673
          ]
# Translation from camera frame to imu frame, imu^T_cam
extrinsicTranslation: # opencv-matrix
   rows: 3
   cols: 1
   dt: d
   data: [-0.0123361991718411, 0.00223558396100998, 0.0049019530415535]


#feature traker paprameters
max_cnt: 150           # max feature number in feature tracking. It is suggested to be raised in VO mode.
min_dist: 30           # min distance between two features
freq: 10                # frequence (Hz) of publish tracking result. At least 10Hz for good estimation. If set 0, the frequence will be same as raw image
F_threshold: 1.0        # ransac threshold (pixel)
show_track: 1           # publish tracking image as topic
equalize: 1             # if image is too dark or light, trun on equalize to find enough features
fisheye: 0              # if using fisheye, trun on it. A circle mask will be loaded to remove edge noisy points

#optimization parameters
max_solver_time: 0.04  # max solver itration time (ms), to guarantee real time
max_num_iterations: 8   # max solver itrations, to guarantee real time
keyframe_parallax: 10.0 # keyframe selection threshold (pixel); if system fails frequently, please try to reduce the "keyframe_parallax"  

#imu parameters       The more accurate parameters you provide, the better performance
acc_n: 1.0          # accelerometer measurement noise standard deviation. # for high freq vehicle, raise it without hesitation
gyr_n: 0.01         # gyroscope measurement noise standard deviation.   
acc_w: 0.001         # accelerometer bias random work noise standard deviation. 
gyr_w: 0.0001       # gyroscope bias random work noise standard deviation.  

g_norm: 9.805       # gravity magnitude

#unsynchronization parameters
estimate_td: 1    ##########                  # online estimate time offset between camera and imu
td: -0.023                          # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)

#rolling shutter parameters
rolling_shutter: 1                      # 0: global shutter camera, 1: rolling shutter camera
rolling_shutter_tr: 0.033               # unit: s. rolling shutter read out time per frame (from data sheet).

#loop closure parameters
loop_closure: 1                    # start loop closure
fast_relocalization: 1            # useful in real-time and large project
load_previous_pose_graph: 1        # load and reuse previous pose graph; load from 'pose_graph_save_path'
pose_graph_save_path: "/home/jiangcx/Documents/ros_ws_rgbd/output/pose_graph/" # save and load path

#visualization parameters
save_image: 0                   # enable this might cause crash; save image in pose graph for visualization prupose; you can close this function by setting 0
visualize_imu_forward: 0        # output imu forward propogation to achieve low latency and high frequence results
visualize_camera_size: 0.4      # size of camera marker in RVIZ

